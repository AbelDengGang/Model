{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和tensor有关的笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 产生tensor的各种方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从numpy生成tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([[0, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "n = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "x = t.from_numpy(n)\n",
    "print(x)\n",
    "# n和x内部的数据是否使用相同的内存呢?\n",
    "n[0][0] = 0\n",
    "# 是的!\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义空tensor 和随机数tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = t.Tensor(3,2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "空tensor,没有初始化,值的范围很大.\n",
    "随机数初始化后的tensor值的范围在0~1之间.\n",
    "==要注意这两者的区别=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1883e+16,  4.5748e-41, -2.7332e+29,  3.0911e-41],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-2.5289e+29,  3.0911e-41,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-2.7335e+29,  3.0911e-41, -2.7335e+29,  3.0911e-41],\n",
       "         [-2.7335e+29,  3.0911e-41,  0.0000e+00,  0.0000e+00]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = t.rand(3,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4425, 0.2156, 0.0283, 0.5273],\n",
       "         [0.3865, 0.5311, 0.1423, 0.4639]],\n",
       "\n",
       "        [[0.7096, 0.7792, 0.6286, 0.3830],\n",
       "         [0.9422, 0.3639, 0.7237, 0.8913]],\n",
       "\n",
       "        [[0.4050, 0.5139, 0.6028, 0.6433],\n",
       "         [0.2190, 0.9309, 0.7384, 0.1902]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过复制的方法生成tensor\n",
    "- 浅拷贝: tensor底层的数据使用同一块内存,改变任意一个,其他的值都会变\n",
    "- 深拷贝: tensor底层的数据使用独立内存,改变一个,其他的值不会变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.)\n"
     ]
    }
   ],
   "source": [
    "# 使用=是浅拷贝\n",
    "x2 = x\n",
    "x[0][0][0] = 9\n",
    "print(x2[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# 使用clone是深拷贝\n",
    "x[0][0][0] = 1\n",
    "x3 = x.clone()\n",
    "x[0][0][0] = 8\n",
    "print(x3[0][0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function detach:\n",
      "\n",
      "detach(...) method of torch.Tensor instance\n",
      "    Returns a new Tensor, detached from the current graph.\n",
      "    \n",
      "    The result will never require gradient.\n",
      "    \n",
      "    .. note::\n",
      "    \n",
      "      Returned Tensor shares the same storage with the original one.\n",
      "      In-place modifications on either of them will be seen, and may trigger\n",
      "      errors in correctness checks.\n",
      "      IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "      (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "      also update the original tensor. Now, these in-place changes will not update the\n",
      "      original tensor anymore, and will instead trigger an error.\n",
      "      For sparse tensors:\n",
      "      In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "      returned tensor will not update the original tensor anymore, and will instead\n",
      "      trigger an error.\n",
      "\n",
      "tensor(7.)\n"
     ]
    }
   ],
   "source": [
    "# detatch返回使用同一片内存的tensor,\n",
    "# 但是这个函数不是让你拷贝数据的,\n",
    "# 而是让tensor从当前的计算图中脱离出来\n",
    "help(x.detach)\n",
    "x4=x.detach()\n",
    "x[0][0][0] = 7\n",
    "print(x4[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从tensor转变成scaler\n",
    "只有0维的tensor才可以转成scaler,否则会报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4388) torch.Size([])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s 虽然只有1个数据,但是它依然是tensor\n",
    "s = x[0][0]\n",
    "print(s,s.shape)\n",
    "type(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43879348039627075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s1 是scaler\n",
    "s1 = s.item()\n",
    "print(s1)\n",
    "type(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensor的数据类型\n",
    "- t.uint8\n",
    "- t.int16\n",
    "- t.int8\n",
    "- t.int32\n",
    "- t.int64\n",
    "- t.int = t.int32\n",
    "- t.float16\n",
    "- t.float32\n",
    "- t.float64\n",
    "- t.float = t.float32\n",
    "- t.double = t.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.uint8"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在CPU还是在GPU上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先创建一个CPU或者GPU的device,然后用tensor.to把tensor转移到device上\n",
    "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4106, 0.6737, 0.0043],\n",
      "        [0.7891, 0.4465, 0.0342],\n",
      "        [0.3430, 0.2912, 0.7660],\n",
      "        [0.0554, 0.4707, 0.2168],\n",
      "        [0.0857, 0.7483, 0.0282]]) cpu\n"
     ]
    }
   ],
   "source": [
    "x = t.rand(5,3)\n",
    "print(x,x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4106, 0.6737, 0.0043],\n",
      "        [0.7891, 0.4465, 0.0342],\n",
      "        [0.3430, 0.2912, 0.7660],\n",
      "        [0.0554, 0.4707, 0.2168],\n",
      "        [0.0857, 0.7483, 0.0282]], device='cuda:0') cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(x,x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to(,dtype=None) 默认情况下dtype是None,保持数据格式不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function to:\n",
      "\n",
      "to(...) method of torch.Tensor instance\n",
      "    to(*args, **kwargs) -> Tensor\n",
      "    \n",
      "    Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "    inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "    \n",
      "    .. note::\n",
      "    \n",
      "        If the ``self`` Tensor already\n",
      "        has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "        Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "        :class:`torch.dtype` and :class:`torch.device`.\n",
      "    \n",
      "    Here are the ways to call ``to``:\n",
      "    \n",
      "    .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "    \n",
      "        Returns a Tensor with the specified :attr:`dtype`\n",
      "    \n",
      "        Args:\n",
      "            memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "            returned Tensor. Default: ``torch.preserve_format``.\n",
      "    \n",
      "    .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "    \n",
      "        Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "        :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "        When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "        the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "        CUDA Tensor.\n",
      "        When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "        already matches the desired conversion.\n",
      "    \n",
      "        Args:\n",
      "            memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "            returned Tensor. Default: ``torch.preserve_format``.\n",
      "    \n",
      "    .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "    \n",
      "        Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "        the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "        asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "        Tensor with pinned memory to a CUDA Tensor.\n",
      "        When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "        already matches the desired conversion.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "        >>> tensor.to(torch.float64)\n",
      "        tensor([[-0.5044,  0.0005],\n",
      "                [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "    \n",
      "        >>> cuda0 = torch.device('cuda:0')\n",
      "        >>> tensor.to(cuda0)\n",
      "        tensor([[-0.5044,  0.0005],\n",
      "                [ 0.3310, -0.0584]], device='cuda:0')\n",
      "    \n",
      "        >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "        tensor([[-0.5044,  0.0005],\n",
      "                [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "    \n",
      "        >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "        >>> tensor.to(other, non_blocking=True)\n",
      "        tensor([[-0.5044,  0.0005],\n",
      "                [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(x.to)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
